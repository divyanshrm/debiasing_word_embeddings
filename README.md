# debiasing_word_embeddings
Word embeddings tend to get biased in certain aspects because of training data is having some gender bias or because of the frequency of a particular word being used with another word is high.
This Project was part of my deep learning specialization projects.
